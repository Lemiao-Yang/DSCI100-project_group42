{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d742328-388b-4584-8325-8c555cddd329",
   "metadata": {},
   "source": [
    "# DSCI Group Project -- Group 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8bd20c-3fb5-48c3-af31-38cd7b92ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(dplyr)\n",
    "library(tidymodels)\n",
    "library(themis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163e83bf-b26d-43b9-b09a-fb0d093453cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "players <- read_csv(\"players.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3da74eb-b96a-4d33-89c9-8816622f15b3",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12bb297-6e2b-46ce-8abc-e33976895f36",
   "metadata": {},
   "source": [
    "In 2023, as part of an ongoing exploration into player engagement and behaviour in online gaming environments, UBC students began collecting gameplay-related data to better understand how individuals interact with both in-game features and external community tools. This project aims to identify which types of players are most likely to stay engaged beyond the game itself, through newsletters, and what personal or behavioural characteristics contribute to that engagement.\n",
    "\n",
    "Online games attract a wide range of players because they allow for diverse play styles including: creative, competitive, social, or exploratory. Research has shown that different demographic and behavioural characteristics shape how players participate in digital spaces. Younger players often interact with fast-paced features more actively (Wohn, 2014), while more experienced players tend to engage more deeply with community-driven aspects of games (Yee, 2006). Although gender differences have also been documented, scholars caution against using gender as a predictive feature in computational models because doing so can reinforce stereotypes and obscure biases within datasets (D’Ignazio & Klein, 2020).\n",
    "    \n",
    "These concerns are especially relevant in our dataset, where approximately 70% of the players identify as male. This demographic imbalance introduces a sampling bias that makes gender-based predictions unreliable and ethically questionable. For this reason, gender is included only descriptively in our exploratory analysis and is not used as a predictor variable in our final model.\n",
    "\n",
    "We were provided with two datasets containing detailed information about players and the worlds they interact with. The Players dataset includes demographic variables (age, gender), behavioural features (total hours played, experience level), and whether a player subscribed to a newsletter. The second dataset, Sessions, contains information about session-level gameplay activity, such as session length, frequency of play, and world type.\n",
    "\n",
    "Using these datasets, our investigation aims to determine whether certain player characteristics are associated with higher levels of community engagement. More specifically, we ask:\n",
    "        \n",
    "        How do player characteristics like total hours played, experience level, and age predict the likelihood of newsletter subscription?\n",
    "\n",
    "Before modelling, we conducted exploratory data analysis to understand the structure of our data. A bar plot of gender distribution revealed the strong male majority mentioned earlier. A second graph visualizing experience levels (Beginner, Intermediate, Advanced) helped illustrate how players differ in self-reported familiarity with gameplay. We also examined newsletter subscription rates through a simple bar chart, establishing a baseline understanding of engagement with out-of-game communication features. These exploratory graphs provide essential context and help identify which variables may meaningfully relate to newsletter subscription.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6944bf7-3bec-4176-89c1-9b30e86e31de",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_distribution <- players |> \n",
    "ggplot(aes(x = played_hours)) +\n",
    "    geom_histogram(binwidth = 0.5, fill = \"blue\") +\n",
    "    labs(x = \"Number of hours played\", y = \"Count\") +\n",
    "    ggtitle(\"Figure 1: Distribution of Number of Hours Played by Gamers\") +\n",
    "    theme(text = element_text(size = 14))\n",
    "\n",
    "play_distribution\n",
    "\n",
    "\n",
    "subscribe <- players |> \n",
    "ggplot(aes(x = subscribe, fill = subscribe)) +\n",
    "    geom_bar() +\n",
    "    labs(x = \"Subscribed?\", y = \"Count\") +\n",
    "    ggtitle(\"Figure 2: Are players Subscribed to their Gaming Newsletter?\") +\n",
    "    theme(text = element_text(size = 14))\n",
    "subscribe\n",
    "\n",
    "\n",
    "experience <- players |> \n",
    "    ggplot(aes(x = experience, fill = experience)) +\n",
    "    geom_bar() +\n",
    "    labs(title = \"Figure 3: Experience Distribution of Players\", x = \"Experience Level\", y = \"Count\") +\n",
    "    theme(text = element_text(size = 14)) \n",
    "experience\n",
    "\n",
    "age_distribution <- players |> \n",
    "    ggplot(aes(x = Age)) +\n",
    "    geom_histogram(binwidth = 5, fill = \"pink\", color = \"red\") +\n",
    "    labs(x = \"Age of player\", y = \"Count\") +\n",
    "    ggtitle(\"Figure 4: Distribution of Ages of Players\") +\n",
    "    theme(text = element_text(size = 12))\n",
    "\n",
    "age_distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea05f6d-399e-4715-8d94-d0d343dc040b",
   "metadata": {},
   "source": [
    "### Data Visualization Analysis\n",
    "\n",
    "Looking at Figure 1, we can note that our graph is significantly skewed to the right, thus most players only played for a few minutes. With Minecraft being a very long game that requires many different steps and ways to complete the game, having gamers who only played for such brief amounts of time may not make the data very accurate in terms of what true Minecraft gamers look like. Looking at Figure 2, we can see that more than half of the gamers chose to subscribe to the newsletter. Figure 3 shows us that most gamers self-identified as Amateur. Finally, Figure 4 shows us that the majority of gamers were just under 20, probably making them university students.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ffc856-1f32-40c7-8270-90f328247dc8",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e3f99e-e090-4a63-b9ec-06c46c502ee2",
   "metadata": {},
   "source": [
    "### How do player characteristics like total hours played, experience level, and age predict the likelihood of newsletter subscription?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bc751a-8adc-457d-b5a1-a29332c5ea77",
   "metadata": {},
   "source": [
    "Before applying the K-NN algorithm, we first need to set a random seed for reproducibility and clean our dataset.\n",
    "\n",
    "We will transform the `subscribe` and `experience` variables into factors since they are categorical. We will also remove any irrelevant variables that won't be used in the model. Lastly, we will remove observations with missing values to ensure our dataset is complete and ready for analysis. The cleaned dataset will be stored in the `clean_players` variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48de7acc-7bea-4ef1-8d9b-cf81500e87f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(6666)\n",
    "\n",
    "clean_players <- players |>\n",
    "    mutate(subscribe = as.factor(subscribe),\n",
    "           experience = as.factor(experience)) |>\n",
    "    select(-hashedEmail, -gender, -name) |>\n",
    "    filter(!is.na(Age)) |>\n",
    "    filter(!is.na(experience)) |>\n",
    "    filter(!is.na(subscribe))\n",
    "\n",
    "head(clean_players)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d4dbd3-4f8d-48c8-9660-a3f57c1192fc",
   "metadata": {},
   "source": [
    "#### Setting Up Training and Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e76735c-839a-4b7c-81c2-e35f15e31860",
   "metadata": {},
   "source": [
    "To start our K-NN classification, we use the `initial_split` function to split our cleaned dataset. 70% of the data will be used for training our model, while the remaining 30% will be used for testing it. We do this because we want to train the algorithm with our data, but still be able to test using the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426bc859-28e0-4e6f-be0b-51f8f75dbeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_split <- initial_split(clean_players, prop = 0.7, strata = subscribe)\n",
    "players_train <- training(players_split)\n",
    "players_test <- testing(players_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8087e2ba-faf3-463c-ae82-2ed7e8d36655",
   "metadata": {},
   "source": [
    "#### Creating a Recipe and Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4e9e7c-e23a-4f8b-8ea7-0b63391c121f",
   "metadata": {},
   "source": [
    "Our next step is to create a recipe. A recipe defines the preprocessing steps we want to apply to our dataset before executing the analysis. In this case, our target variable is subscribe, and we will use `Age`, `played_hours`, and `experience` as predictor variables. To ensure that no single variable dominates the model due to scale differences, we will scale and center *Age* and *played_hours*. To help our model, we're also going to upsample the *subscribe* variable. This step will prevent the model from being biased towards the majority class (i.e. players who did subscribe).\n",
    "\n",
    "Finally, we will use the `nearest_neighbors` function to specify that our analysis will use K-NN classification!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7187f415-24b0-4061-a7e7-4939d9f14ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_recipe <- recipe(subscribe ~ ., data = players_train) |>\n",
    "    step_scale(Age, played_hours) |>\n",
    "    step_center(Age, played_hours) |>\n",
    "    step_upsample(subscribe, over_ratio = 1, skip = TRUE)\n",
    "players_recipe\n",
    "\n",
    "knn_spec_tuned <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "    set_engine(\"kknn\") |>\n",
    "    set_mode(\"classification\")\n",
    "knn_spec_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c18de8-c41e-4f26-8936-b08a637aa97c",
   "metadata": {},
   "source": [
    "#### Using 5 Fold Cross Validation and Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c6b96a-91c3-4690-b2c6-12f8530baec8",
   "metadata": {},
   "source": [
    "Now, we will set up 5-fold cross-validation for the training set. Cross-validation will evaluate the performance of each model with different k-values by training on a portion of the data and testing it on the remaining part. This process is repeated multiple times to obtain an average result. This step provides a more reliable estimate of our algorithm's ability to predict the `subscribe` variable through its multiple tests. \n",
    "\n",
    "We're going to define our grid by giving a large range for the neighbors parameter in our K-NN model. \n",
    "\n",
    "Finally, we're going to set up our workflow. We want to combine our recipe, our type of model, and the cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cdab7f-671c-4c72-84ae-9f936e184a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_vfold <- vfold_cv(players_train, v = 5, strata = subscribe)\n",
    "k_vals <- tibble(neighbors = seq(from = 1, to = 100, by = 1))\n",
    "\n",
    "knn_tuned_fit <- workflow() |>\n",
    "    add_recipe(players_recipe) |>\n",
    "    add_model(knn_spec_tuned) |>\n",
    "    tune_grid(resamples = players_vfold, grid = k_vals) |>\n",
    "    collect_metrics()\n",
    "knn_tuned_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d1ac73-ba3b-4c5f-a12c-4badb3ab449b",
   "metadata": {},
   "source": [
    "#### Visualize Accuracy with Different K Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387bf7d7-549d-42da-baaa-bfef4956e018",
   "metadata": {},
   "source": [
    "Now that we've fully trained our model, it's time to visualize the accuracy for each value of k (number of neighbors). To do so, we want to create a plot that visualizes the relationship between k and its accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a0d3b0-86c2-425b-a9b8-e63f231ec804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters and selects only rows that are accuracy metric\n",
    "accuracy <- knn_tuned_fit |>\n",
    "    filter(.metric == \"accuracy\")\n",
    "\n",
    "accuracy_plot <- accuracy |>\n",
    "    ggplot(aes(x = neighbors, y = mean)) +\n",
    "    geom_point() +\n",
    "    labs(x = \"Number of Neighbors\",\n",
    "         y = \"Mean Value of Accuracy\") +\n",
    "    ggtitle(\"Figure 1: The Relationship between Number of Neighbors (k) and Accuracy\") +\n",
    "    theme(text = element_text(size = 11))\n",
    "accuracy_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac47ae1-c2df-469d-a8e5-b43efd717a5a",
   "metadata": {},
   "source": [
    "#### Find the Best K and Fitting it in Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd08fb24-c4af-488a-8349-d230e30b6720",
   "metadata": {},
   "source": [
    "From our visual, we can use the function `slice_max` to find the number of k-neighbors with the highest accuracy. This will also allow us to know the optimal number of neighbours to use in our final model, and we will name this `best_k`. \n",
    "\n",
    "With `best_k`, we will specify our optimal model! We'll create our final workflow, which again, will combine all of our previous steps — now with our `best_k`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc18f8fe-2ce8-4e1e-966b-951f268fce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best number of neighbors for our model\n",
    "best_k <- accuracy |>\n",
    "    slice_max(mean) |>\n",
    "    pull(neighbors)\n",
    "best_k\n",
    "\n",
    "# Optimizing model with new value of k\n",
    "knn_spec_best <- nearest_neighbor(weight_func = \"rectangular\", neighbor = best_k) |>\n",
    "    set_engine(\"kknn\") |>\n",
    "    set_mode(\"classification\")\n",
    "\n",
    "# Our final workflow!\n",
    "knn_best_fit <- workflow() |>\n",
    "    add_recipe(players_recipe) |>\n",
    "    add_model(knn_spec_best) |>\n",
    "    fit(players_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826a28cd-37b0-452d-aa41-149f37c1558c",
   "metadata": {},
   "source": [
    "#### Predict Using Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623bc088-c7d7-4752-8759-c07ea8d605bc",
   "metadata": {},
   "source": [
    "After training the K-NN model with the optimal number of neighbors, We are going to use the test dataset to make predictions on the `subscribe` variable. We're going to evaluate the model’s performance using two metrics: accuracy and kappa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7100ed5e-8c41-413e-8df3-98312f78cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscribe_predictions <- predict(knn_best_fit, players_test) |>\n",
    "    bind_cols(players_test)\n",
    "\n",
    "subscribe_metrics <- subscribe_predictions |>\n",
    "    metrics(truth = subscribe, estimate = .pred_class)\n",
    "\n",
    "subscribe_metrics\n",
    "subscribe_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc321569-fc14-475b-b9ad-963fa20f259a",
   "metadata": {},
   "source": [
    "**The model achieves an accuracy of 77.97%**, meaning it correctly predicts the subscription status of players about 78% of the time. \n",
    "\n",
    "These results suggest that the model performs well, but there may still be room for improvement in terms of agreement between predicted and true outcomes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
